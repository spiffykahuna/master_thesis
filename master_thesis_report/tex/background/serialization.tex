\subsection{Data serialization}
\begin{quotation}
\textit{
Serialization is a process for converting a data structure or object into a format that
can be transmitted through a wire, or stored somewhere for later
use~\cite{json_vs_yaml}.
}
\end{quotation}
Previous sections described some possible implementations of Service Oriented
Architecture. These technologies use client-server communication and
send information between client and server, that need to be understood at both
destinations. No matter how this information is sent, using resource/object representation in case of REST or
request/response message in case of RPC, it needs to be converted to format that
can be decoded and understood with the user of that information. Common transmission scenario
can look like:
\begin{enumerate}
  \item Client wants to send a some information to a server. It has some data in
  memory and that data is in application specific format(object structure, text,
  image, movie file).
  \item Client \textbf{packs} his information into a message and sends it to
  server using any possible transport channel(email, paper mail, homing pigeon, tcp
  socket, etc).
  \item Server receives this message, \textbf{unpacks} the message and gets a
  piece of information that client wanted to send.
  \item Server reads the information and decides what to do with it.
\end{enumerate}

Process of packing information is called \textbf{serialization} (also deflating
or marshalling) and process of unpacking is called \textbf{deserialization}
(inflating or unmarshalling). 

There are lots of different ways and formats that can
be used. Which method and format to choose depends on the requirements set up on
the object or data, and the use for the serialization (sending or storing). The choice
may also affect the size of the serialized data as well as serialization/deserialization
performance in terms of processing time and memory usage~\cite{json_vs_yaml}.
Next section describes possible serialization solutions.

\subsubsection{Serialization technologies}
Serialization is supported by many programming languages, which provide tools
and libraries for data serialization to different formats. Article
~\cite{wikipedia:comparison_of_data_serialization_formats}
provides a summary of well known data serialization formats.
Most of them could be divided into two groups: human-readable text based formats
and binary formats. Both groups have their own advantages and disadvantages.
\autoref{tbl:data_ser_formats} shortly describes them. 


\begin{longtabu} to \textwidth {|L|X|X|}
	\caption{Comparison of binary and human-readable serialization formats}
	\label{tbl:data_ser_formats}	
\hline 
\multicolumn{1}{|l|}{\textbf{Property}} & 
\multicolumn{1}{l|}{\textbf{Binary formats}} & 
\multicolumn{1}{l|}{\textbf{Human-readable formats}} \\ 
\hline 
\endfirsthead

\multicolumn{3}{l}%
{{\bfseries \tablename\ \thetable{} -- continued from previous page}} \\
\hline 
\multicolumn{1}{|l|}{\textbf{Property}} & 
\multicolumn{1}{l|}{\textbf{Binary formats}} & 
\multicolumn{1}{l|}{\textbf{Human-readable formats}} \\ 
\hline 
\endhead

\hline \multicolumn{3}{|r|}{{Continued on next page}} \\ \hline
\endfoot

% \hline \hline
\endlastfoot

		Format examples &
		Protocol Buffers from Google \newline 
		{Apache Thrift(TBinaryProtocol)} \newline
		BSON used in MongoDB database \newline
		MessagePack(\url{http://msgpack.org})\newline
		and most of native serialization
		mechanisms in various programming languages(Java, Python, .NET framework,
		C++ BOOST serialization) &
		XML \newline JSON \newline \gls{YAML}
	
	    \tabularnewline
		\hline	  
		
		Advantages & 
		The two main reasons why binary formats are usually proposed
		are for \textbf{size} and \textbf{speed}. \newline
		Typically use fewer CPU cycles and require less memory.
		Binary data is transformed as is, no need to encode data bytes( image, video,
		etc)
		Better for larger datasets \newline
		Random data access.
		

		
		&
		
		Do not have to write extra tools to debug the input and output; you can open
		the serialized output with a text editor to see if it looks right. \newline
		Self-descriptive and easily recoverable. \newline
		No need to use programming issues like sizeof and little-endian vs.
		big-endian. \newline
		Platform and programming language independent. \newline
		Broad support by tools and libraries \newline
		
		
		
		
		\tabularnewline
		\hline
		Disadvantages &
		Not verbose. Hard to debug. \newline
		Fixed data structures. Hard to extend. \newline
		Not self-descriptive( it is hard to understand for human where actual data
		starts in the array of bytes, ), has no data description( metadata, layout
		of the data)\newline Require special software and  highly customized data
		access algorithms.
		Hard to recover data after software version change (remember different MS
		office formats)
				
		&
		
		Binary data needs to be converted to text form( Base64). \newline
		Additional processing overhead (CPU and memory consumption). \newline
		Lot of redundancy.
		Representing your data as text is not always easy/possible or
		reasonable(video/audio streams, large matrices with numbers)
				
				
		\tabularnewline
		\hline
	%\end{tabularx} 

\end{longtabu}

Text-based nature makes human-readable format a suitable choice
for applications where humans are expected to see the data,
such as in document editing or where debugging information
is needed. Binary formats are better for high speed and low latency
applications.

\subsubsection{XML vs JSON}
\label{sec:xml_vs_json}
Choosing the right serialization format mostly depends on your data and
application. But if there is no any constraint what protocol to use, text
protocols are more preferable. They give you advantages like: verbosity,
extensibility, portability.

Most popular human and machine readable serialization formats are XML and JSON.

\paragraph{XML} ~\\
\begin{quotation}
\textit{
XML is hugely important. Dr Charles Goldfarb, who was personally involved in its
invention, claims it to be “the holy grail of computing, solving the problem of universal data interchange between dissimilar systems.” It is also a handy format for everything from configuration files to data and documents of almost any type
~\cite{xml_intro}.}
\end{quotation} 

The fundamental design considerations of XML include
simplicity and human readability~\cite{NurseitovPRI09}.
W3C\footnote{World Wide Web Consortium} specifies the design goals for XML
like~\cite{w3c_xml}:
\begin{enumerate}
  \item XML shall be straightforwardly usable over the Internet.
  \item XML shall support a wide variety of applications.
  \item XML shall be compatible with SGML\footnotemark.
  \item It shall be easy to write programs which process XML documents.
  \item The number of optional features in XML is to be kept to the absolute minimum, ideally zero.
  \item XML documents should be human-legible and reasonably clear.
  \item The XML design should be prepared quickly.
  \item The design of XML shall be formal and concise.
  \item XML documents shall be easy to create.
  \item Terseness in XML markup is of minimal importance.  
\end{enumerate}
\footnotetext{Standard Generalized Markup Language. SGML is a system for
defining markup languages. Authors mark up their documents by representing
structural, presentational, and semantic information alongside
content.~\cite{html_spec}}

The primary uses for XML are Remote Procedure Calls and object serialization for transfer of
data between applications. 

Simple data structure in XML looks like:

\begin{listing}[H]
\begin{minted}[frame=lines,
               framesep=2mm]{xml}
<person>
	<firstname>John</firstname>
	<surname>Smith</surname>
	<email>john.smith@example.com</email>
	<mobile>1234567890</mobile>
</person>
\end{minted}
\caption{XML structure describing abstract person}
\label{lst:xml_person_example}
\end{listing}


\paragraph{JSON} ~\\
\label{sec:json_description}
JSON (JavaScript Object Notation) is a lightweight data-interchange
format~\cite{json_org}.It is easy for humans to read and write and also is
easy for machines to parse and generate. JSON is based on JavaScript
Programming Language and is directly supported inside JavaScript. It has library
bindings for popular programming languages.

JSON is built on two structures~\cite{json_org}:
\begin{itemize}
  \item A collection of name/value pairs. In various languages, this is realized
  as an object, record, struct, dictionary, hash table, keyed list, or associative array.
  \item An ordered list of values. In most languages, this is realized as an
  array, vector, list, or sequence.
\end{itemize}

The same structure from XML section looks in JSON encoding like:
\begin{listing}[H]
\begin{minted}[frame=lines,
               framesep=2mm]{json}
{
	"person" : {
		"firstname" : "John",
		"surname" : "Smith",
		"email" : "john.smith@example.com",
		"mobile" : 1234567890
	}
}
\end{minted}
\caption{JSON structure describing abstract person}
\label{lst:json_person_example}
\end{listing}

JSON value can be a string in double quotes, or a number, or true or false or
null, or an object or an array. These structures can be nested.

JSON specification is quite easy and it is  described using only one
page~\cite{json_org}. This page provides also a list of programming languages
and libraries that support JSON. 

Research in different documents ~\cite{5931189,NurseitovPRI09} showed that
that JSON is faster and uses fewer resources than its XML
counterpart.
Transferring data in the form of JSON instead of XML can speed up the server
data transfer efficiency.

This is because XML is characterised by its rich verbosity,
meaning that it requires a separate start-tag and end-tag for describing the content.
As JSON does not use end-tags at all for the description of the content, the
resulting number of bytes is smaller.
Paper ~\cite{5931189} contains performance analysis of mobile device(Apple
iPhone), which executes different tests working with XML, JSON and SOAP.
Research results prove that SOAP and XML have overhead over JSON.

To make messages more smaller binary formats or compression(for example gzip)  
should be used. There is also available newly emerged Efficient XML Interchange
(EXI)\footnote{It was adopted as a Candidate Recommendation by the
W3C, for more information see
\url{http://www.w3.org/TR/2013/CR-exi-profile-20130416/}} standard for binary XML encoding. It is expected to become an alternative to XML for exchanging data between embedded systems\cite{6120046}.

\paragraph{Parsers} ~\\
All JSON and XML parsers can be divided into two groups: stream-based and
tree-based. Stream based parsers (also known as Simple API for XML(SAX)) are
event-based. They read input message sequentially and signals the application when a new component has
been read. They raise notifications on reaching different document parts and
programmer needs to decide what to do with this part of document( store or
skip). Such parsers require less resources than tree-based, because they do not
need to keep whole document in memory.

Tree-based parsers load whole message to memory and then parse it. They create a
tree of this document (also known as Document Object Model (DOM)) and return it
to application developer. Programmer receives whole document tree and is able to
extract needed parts from that.

Although stream-based parsers often
have better performance than tree-based parsers, they make application code more
complex due to their event-driven nature.

Document serializers work using similar scheme.

\subsubsection{Is there a right serialization format?}

There is no direct answer for that question.
The format and the parser used has to be chosen according your application
constraints and requirements. Binary formats give you a small message size and
reduce required amount of CPU cycles for data processing, but there is a lack of
verbosity and it is hard to extract data without using additional tools. Text
based formats reduce development and debugging time, but they have overhead
because of their verbosity. There is a hardware resources/ development
time tradeoff in this problem. Some calculations should be made before making a
decision.

Whatever format you choose, binary or human-readable, this should be  a
standard and open format.
It means that this format should be supported by different software tools and programming
languages,  you can read its specification and understand its features, your
people can study it more quickly, system integration becomes more easy, because
other system understand it too. If it is a production standard, there is a
chance that it will not essentially change in near future.

Text formats like XML and JSON are used in various production systems all over the world and are good
candidates to be in your system.




